# -*- coding: utf-8 -*-
"""Copia di ANNDL-challenge1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TK6Ml5cFjPaJaMxQKY_hncjzBwp5uSph
"""

from datetime import datetime
from keras.preprocessing.image import ImageDataGenerator
import tensorflow as tf
# import tensorflow_addons as tfa
import numpy as np
import os
import random
# import pandas as pd
# import seaborn as sns
# import matplotlib as mpl
# import visualkeras
# import scipy
# import sklearn
# import skimage
# import pyyaml
# import imutils
# import cv2
# import tqdm
# import psutil
# import h5py
# import tensorboard
# from PIL import Image
# from time import time
import matplotlib.pyplot as plt

# from sklearn.model_selection import train_test_split
# from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix
# from tensorflow.python.keras.callbacks import TensorBoard

"""
!pip install visualkeras
!pip install scikit-learn
!pip install scikit-image
!pip install pyyaml
!pip install imutils
!pip install opencv-python
!pip install tensorboard
!pip install tensorflow_addons
!pip install google.colab
"""

tfk = tf.keras
tfkl = tf.keras.layers
print(tf.__version__)

# USE GPUS
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    # Restrict TensorFlow to only use the first GPU
    try:
        tf.config.set_visible_devices(gpus[0], 'GPU')
        logical_gpus = tf.config.list_logical_devices('GPU')
        print(len(gpus), "Physical GPUs,", len(logical_gpus), "Logical GPU")
    except RuntimeError as e:
        # Visible devices must be set before GPUs have been initialized
        print(e)

"""PARAMETERS"""
preprocessing_function = tf.keras.applications.vgg19.preprocess_input
preprocessing_function_name = "vgg19"
seed = 42
# dataset
dataset_dir = "./"
training_dir = os.path.join(dataset_dir, 'training_data_final')
# define labels
labels = ['species 1',  # 0
          'species 2',  # 1
          'species 3',  # 2
          'species 4',  # 3
          'species 5',  # 4
          'species 6',  # 5
          'species 7',  # 6
          'species 8']  # 7
# if path_tl=="" then we make the transfer learning part, otherwise we use the path to load that
path_tl = "C:\\Users\\emili\\OneDrive - Politecnico di Milano" \
          "\\Desktop\\Backup\\POLITECNICO\\5ANNO\\1-ANNDL\\laboratory\\data_augmentation_challenge_1" \
          "\\CNN_Aug_tl_Best_Nov21_22-51-21"

random.seed(seed)
os.environ['PYTHONHASHSEED'] = str(seed)
np.random.seed(seed)
tf.random.set_seed(seed)
tf.compat.v1.set_random_seed(seed)

## create instance without augmentation

"""
VISUALIZE BATCH
"""


def get_next_batch(generator):
    batch = next(generator)

    image = batch[0]  # first position is the image
    target = batch[1]  # second position is the target

    print("(Input) image shape:", image.shape)
    print("Target shape:", target.shape)

    # Visualize only the first sample
    image = image[0]
    target = target[0]
    target_idx = np.argmax(target)
    print()
    print("Categorical label:", target)
    print("Label:", target_idx)
    print("Class name:", labels[target_idx])
    fig = plt.figure(figsize=(6, 4))
    plt.imshow(np.uint8(image))

    return batch


def create_folders_and_callbacks(model_name):
    exps_dir = os.path.join(dataset_dir, 'data_augmentation_tl_challenge_1')
    if not os.path.exists(exps_dir):
        os.makedirs(exps_dir)

    now = datetime.now().strftime('%b%d_%H-%M-%S')

    exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))
    if not os.path.exists(exp_dir):
        os.makedirs(exp_dir)

    callbacks = []

    # Model checkpoint
    # ----------------
    ckpt_dir = os.path.join(exp_dir, 'ckpts_challenge_1')
    if not os.path.exists(ckpt_dir):
        os.makedirs(ckpt_dir)

    ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp.ckpt'),
                                                       save_weights_only=False,  # True to save only weights
                                                       save_best_only=False)  # True to save only the best epoch
    callbacks.append(ckpt_callback)

    # Visualize Learning on Tensorboard
    # ---------------------------------
    tb_dir = os.path.join(exp_dir, 'tb_logs')
    if not os.path.exists(tb_dir):
        os.makedirs(tb_dir)

    # By default shows losses and metrics for both training and validation
    tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,
                                                 profile_batch=0,
                                                 histogram_freq=1)  # if > 0 (epochs) shows weights histograms
    callbacks.append(tb_callback)

    # Early Stopping
    # --------------
    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, mode='max',
                                                   restore_best_weights=True)
    callbacks.append(es_callback)

    return callbacks


def plot_dataset():
    plot_data_generator = ImageDataGenerator()
    return plot_data_generator.flow_from_directory(directory=training_dir, target_size=(96, 96),
                                                   color_mode='rgb',
                                                   classes=None, batch_size=8, shuffle=False, seed=seed,
                                                   subset='training')


plot_data_gen = plot_dataset()

# Get a sample from dataset and show info
_ = get_next_batch(plot_data_gen)

"""NO AUGMENTATION"""


def no_augmentation():
    noaug_train_data_gen = ImageDataGenerator(rescale=1 / 255., validation_split=0.2,
                                              preprocessing_function=preprocessing_function)
    noaug_train_gen_loc = noaug_train_data_gen.flow_from_directory(directory=training_dir, target_size=(96, 96),
                                                                   color_mode='rgb',
                                                                   classes=None, batch_size=8, shuffle=True, seed=seed,
                                                                   subset='training')
    noaug_valid_gen_loc = noaug_train_data_gen.flow_from_directory(directory=training_dir, target_size=(96, 96),
                                                                   color_mode='rgb',
                                                                   classes=None, batch_size=8, shuffle=False, seed=seed,
                                                                   subset='validation')

    # check classes
    print('Assigned labels')
    print(noaug_train_gen_loc.class_indices)
    print()
    print('Target classes')
    print(noaug_train_gen_loc.classes)

    return [noaug_train_gen_loc, noaug_valid_gen_loc]


[noaug_train_gen, noaug_valid_gen] = no_augmentation()

"""AUGMENTATION"""


def augmentation():
    aug_train_data_gen = ImageDataGenerator(rotation_range=30,
                                            height_shift_range=50,
                                            width_shift_range=50,
                                            zoom_range=0.3,
                                            horizontal_flip=True,
                                            vertical_flip=True,
                                            fill_mode='reflect',
                                            rescale=1 / 255.,
                                            preprocessing_function=preprocessing_function)

    aug_train_gen = aug_train_data_gen.flow_from_directory(directory=training_dir, target_size=(96, 96),
                                                           color_mode='rgb',
                                                           classes=None, batch_size=8, shuffle=True, seed=seed)

    # Get sample image
    image = next(plot_data_gen)[0][4]

    # Create an instance of ImageDataGenerator for each transformation
    rot_gen = ImageDataGenerator(rotation_range=30)  # rotated randomly of +/- 30 deg
    shift_gen = ImageDataGenerator(width_shift_range=50)  # shift randomly of a value ranging from -50 to 50 pixels
    zoom_gen = ImageDataGenerator(zoom_range=0.3)  # maximum 30% zoomed
    flip_gen = ImageDataGenerator(horizontal_flip=True)  # flip horizontally

    # Get random transformations
    rot_t = rot_gen.get_random_transform(img_shape=(256, 256), seed=seed)
    print('Rotation:', rot_t, '\n')
    shift_t = shift_gen.get_random_transform(img_shape=(256, 256), seed=seed)
    print('Shift:', shift_t, '\n')
    zoom_t = zoom_gen.get_random_transform(img_shape=(256, 256), seed=seed)
    print('Zoom:', zoom_t, '\n')
    flip_t = flip_gen.get_random_transform(img_shape=(256, 256), seed=seed)
    print('Flip:', flip_t, '\n')

    # Apply the transformation
    gen = ImageDataGenerator(fill_mode='constant', cval=0.)
    rotated = gen.apply_transform(image, rot_t)
    shifted = gen.apply_transform(image, shift_t)
    zoomed = gen.apply_transform(image, zoom_t)
    flipped = gen.apply_transform(image, flip_t)

    # Plot original and augmented images
    fig, ax = plt.subplots(1, 5, figsize=(15, 45))
    ax[0].imshow(np.uint8(image))
    ax[0].set_title('Original')
    ax[1].imshow(np.uint8(rotated))
    ax[1].set_title('Rotated')
    ax[2].imshow(np.uint8(shifted))
    ax[2].set_title('Shifted')
    ax[3].imshow(np.uint8(zoomed))
    ax[3].set_title('Zoomed')
    ax[4].imshow(np.uint8(flipped))
    ax[4].set_title('Flipped')

    ## Combine multiple transformations
    gen = ImageDataGenerator(rotation_range=30,
                             height_shift_range=50,
                             width_shift_range=50,
                             zoom_range=0.3,
                             horizontal_flip=True,
                             vertical_flip=True,
                             fill_mode='reflect')

    # Get random transformation
    t = gen.get_random_transform(img_shape=(256, 256), seed=seed)
    print("Transform:", t)

    # Apply the transformation
    augmented = gen.apply_transform(image, t)

    # Plot original and augmented images
    fig, ax = plt.subplots(1, 2, figsize=(15, 30))
    ax[0].imshow(np.uint8(image))
    ax[0].set_title("Original")
    ax[1].imshow(np.uint8(augmented))
    ax[1].set_title("Augmented")
    plt.show()

    return aug_train_gen


aug_train_gen = augmentation()

"""TRANSFER LEARNING"""


def transfer_learning_vgg19():
    print("*** TRANSFER LEARNING ***")

    ## download and plot preprocessing_function_name model
    vgg19 = tfk.applications.vgg19.VGG19(
        include_top=False,
        weights="imagenet",
        input_shape=(96, 96, 3)
    )
    vgg19.summary()

    # Use vgg19 as feature extractor
    vgg19.trainable = False

    inputs = tfk.Input(shape=(96, 96, 3))
    x = tfkl.Resizing(96, 96, interpolation="bicubic")(inputs)
    x = vgg19(x)
    x = tfkl.AveragePooling2D(pool_size=(2, 2), name='Pooling-2')(x)
    x = tfkl.Flatten(name='Flattening')(x)
    x = tfkl.Dropout(0.5, seed=seed)(x)
    x = tfkl.Dense(
        1024,
        activation='relu',
        kernel_initializer=tfk.initializers.GlorotUniform(seed))(x)
    x = tfkl.Dropout(0.5, seed=seed)(x)
    outputs = tfkl.Dense(
        8,
        activation='softmax',
        kernel_initializer=tfk.initializers.GlorotUniform(seed))(x)

    # Create folders and callbacks and fit
    aug_tl_callbacks = create_folders_and_callbacks(model_name='CNN_Aug_tl')

    # Connect input and output through the Model class
    aug_tl_model = tfk.Model(inputs=inputs, outputs=outputs, name="vgg19")

    # Compile the model
    aug_tl_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')
    aug_tl_model.summary()

    # Train the model
    input_shape = (96, 96, 3)
    epochs = 200

    aug_tl_history = aug_tl_model.fit(
        x=aug_train_gen,
        epochs=epochs,
        validation_data=noaug_valid_gen,
        callbacks=aug_tl_callbacks,
    ).history

    ## Save best epoch model
    now = datetime.now().strftime('%b%d_%H-%M-%S')
    filename = dataset_dir + "/data_augmentation_challenge_1/CNN_Aug_tl_vgg19_Best_" + str(now)
    aug_tl_model.save(filename)
    del aug_tl_model

    ## Plot the training
    plt.figure(figsize=(15, 5))
    plt.plot(aug_tl_history['loss'], alpha=.3, color='#4D61E2', linestyle='--')
    plt.plot(aug_tl_history['val_loss'], label='Transfer Learning', alpha=.8, color='#4D61E2')
    plt.legend(loc='upper left')
    plt.title('Categorical Crossentropy')
    plt.grid(alpha=.3)

    plt.figure(figsize=(15, 5))
    plt.plot(aug_tl_history['accuracy'], alpha=.3, color='#4D61E2', linestyle='--')
    plt.plot(aug_tl_history['val_accuracy'], label='Transfer Learning', alpha=.8, color='#4D61E2')
    plt.legend(loc='upper left')
    plt.title('Accuracy')
    plt.grid(alpha=.3)

    plt.show()
    return filename


if not path_tl:
    path_tl = transfer_learning_vgg19()
    print(path_tl)


"""FINE TUNING"""


def fine_tuning(path):
    print("*** FINE TUNING ***")
    epochs = 300

    # Re-load the model after transfer learning
    aug_ft_model = tfk.models.load_model(path)
    aug_ft_model.summary()

    # Set all vgg19 layers to True
    aug_ft_model.get_layer('vgg19').trainable = True
    for i, layer in enumerate(aug_ft_model.get_layer('vgg19').layers):
        print(i, layer.name, layer.trainable)

    # Freeze first N layers, e.g., until 15th
    for i, layer in enumerate(aug_ft_model.get_layer('vgg19').layers[-7:]):
        layer.trainable = False
    for i, layer in enumerate(aug_ft_model.get_layer('vgg19').layers):
        print(i, layer.name, layer.trainable)
    aug_ft_model.summary()

    # Compile the model
    aug_ft_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(1e-4),
                         metrics='accuracy')

    # Create folders and callbacks and fit
    aug_ft_callbacks = create_folders_and_callbacks(model_name='CNN_Aug_ft')

    # Fine-tune the model
    aug_ft_history = aug_ft_model.fit(
        x=aug_train_gen,
        epochs=epochs,
        validation_data=noaug_valid_gen,
        callbacks=aug_ft_callbacks,
    ).history

    # Plot the training
    plt.figure(figsize=(15, 5))
    plt.plot(aug_ft_history['loss'], alpha=.3, color='#4D61E2', linestyle='--')
    plt.plot(aug_ft_history['val_loss'], label='Transfer Learning', alpha=.8, color='#4D61E2')
    plt.legend(loc='upper left')
    plt.title('Categorical Crossentropy')
    plt.grid(alpha=.3)

    plt.figure(figsize=(15, 5))
    plt.plot(aug_ft_history['accuracy'], alpha=.3, color='#4D61E2', linestyle='--')
    plt.plot(aug_ft_history['val_accuracy'], label='Transfer Learning', alpha=.8, color='#4D61E2')
    plt.legend(loc='upper left')
    plt.title('Accuracy')
    plt.grid(alpha=.3)

    plt.show()

    ## Save best epoch model
    now = datetime.now().strftime('%b%d_%H-%M-%S')
    save_path = dataset_dir + "/data_augmentation_challenge_1/CNN_Aug_ft_Best_" + str(now)
    aug_ft_model.save(save_path)
    return save_path


path_ft = fine_tuning(path_tl)
print(path_ft)

# tensorboard
# !tensorboard --logdir
